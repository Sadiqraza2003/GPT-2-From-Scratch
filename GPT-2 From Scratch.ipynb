{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMN341eyaRnxOjMsZnsp4ei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["! pip3 install Tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KF_j98l4Sw4d","executionInfo":{"status":"ok","timestamp":1734244841398,"user_tz":-330,"elapsed":4692,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"917c4dca-ca77-4129-874e-699c45ae4f03"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from Tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from Tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->Tiktoken) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->Tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->Tiktoken) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->Tiktoken) (2024.8.30)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Tiktoken\n","Successfully installed Tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import tiktoken\n","tokenizer = tiktoken.encoding_for_model(\"gpt-2\")"],"metadata":{"id":"H7PygllDRj_X","executionInfo":{"status":"ok","timestamp":1734244850080,"user_tz":-330,"elapsed":8685,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZJ9nknlZRWL1","executionInfo":{"status":"ok","timestamp":1734244850081,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"outputs":[],"source":["GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,    # Vocabulary size\n","    \"context_length\": 1024, # Context length\n","    \"emb_dim\": 768,         # Embedding dimension\n","    \"n_heads\": 12,          # Number of attention heads\n","    \"n_layers\": 12,         # Number of layers\n","    \"drop_rate\": 0.1,       # Dropout rate\n","    \"qkv_bias\": False       # Query-Key-Value bias\n","}"]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        assert (d_out % num_heads == 0), \\\n","            \"d_out must be divisible by num_heads\"\n","\n","        self.d_out = d_out\n","        self.num_heads = num_heads\n","        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n","\n","        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer(\n","            \"mask\",\n","            torch.triu(torch.ones(context_length, context_length),\n","                       diagonal=1)\n","        )\n","\n","    def forward(self, x):\n","        b, num_tokens, d_in = x.shape\n","\n","        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n","        queries = self.W_query(x)\n","        values = self.W_value(x)\n","\n","        # We implicitly split the matrix by adding a `num_heads` dimension\n","        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","        keys = keys.transpose(1, 2)\n","        queries = queries.transpose(1, 2)\n","        values = values.transpose(1, 2)\n","\n","        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n","        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n","\n","        # Original mask truncated to the number of tokens and converted to boolean\n","        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","\n","        # Use the mask to fill attention scores\n","        attn_scores.masked_fill_(mask_bool, -torch.inf)\n","\n","        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","        attn_weights = self.dropout(attn_weights)\n","\n","        # Shape: (b, num_tokens, num_heads, head_dim)\n","        context_vec = (attn_weights @ values).transpose(1, 2)\n","\n","        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n","        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n","        context_vec = self.out_proj(context_vec) # optional projection\n","\n","        return context_vec"],"metadata":{"id":"9KUuntvoJKJZ","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":6,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    def __init__(self, emb_dim):\n","        super().__init__()\n","        self.eps = 1e-5\n","        self.scale = nn.Parameter(torch.ones(emb_dim))\n","        self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        var = x.var(dim=-1, keepdim=True, unbiased=False)\n","        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n","        return self.scale * norm_x + self.shift"],"metadata":{"id":"j7yiYjW3TOH1","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":6,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["This specific implementation of layer Normalization operates on the last dimension of the input tensor x, which represents the embedding dimension (emb_dim).\n","\n","The variable eps is a small constant (epsilon) added to the variance to prevent division by zero during normalization.\n","\n","The scale and shift are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task.\n","\n","This allows the model to learn appropriate scaling and shifting that best suit the data it is processing."],"metadata":{"id":"MP7bbPp1WYhE"}},{"cell_type":"markdown","source":["Formula of GELU activation Function which use in GPT-2   \"GELU(x)=0.5⋅x(1+tanh(\n","π\n","2\n","​\n","\n","​\n"," ⋅(x+0.044715⋅x\n","3\n"," )))\""],"metadata":{"id":"b2BIG5vNUN8n"}},{"cell_type":"code","source":["class GELU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(\n","            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n","            (x + 0.044715 * torch.pow(x, 3))\n","        ))"],"metadata":{"id":"4SeuLuh3Trod","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Feed Forward block consis of three block\n","\n","1: Linear Layer (768 , 4*768)\n","\n","2: Gelu Activation Function\n","\n","3: Linear Layer (4*768 , 768)"],"metadata":{"id":"YgWMzqgYYOLp"}},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n","            GELU(), ## Activation\n","            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)"],"metadata":{"id":"yvlG1YZITxaq","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.att = MultiHeadAttention(\n","            d_in=cfg[\"emb_dim\"],\n","            d_out=cfg[\"emb_dim\"],\n","            context_length=cfg[\"context_length\"],\n","            num_heads=cfg[\"n_heads\"],\n","            dropout=cfg[\"drop_rate\"],\n","            qkv_bias=cfg[\"qkv_bias\"])\n","        self.ff = FeedForward(cfg)\n","        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n","        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n","        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    def forward(self, x):\n","        # Shortcut connection for attention block\n","        shortcut = x\n","        x = self.norm1(x)\n","        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        # Shortcut connection for feed forward block\n","        shortcut = x\n","        x = self.norm2(x)\n","        x = self.ff(x)\n","        x = self.drop_shortcut(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        return x"],"metadata":{"id":"2FX-Z_iVoxVY","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.trf_blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","\n","        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(\n","            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n","        )\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits"],"metadata":{"id":"OPVl99ycz00J","executionInfo":{"status":"ok","timestamp":1734244850082,"user_tz":-330,"elapsed":4,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Replace\n","torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","\n","# Define the 'batch' variable with sample data\n","# Assuming your input is a sequence of token IDs\n","# Replace this with your actual input data\n","batch = torch.randint(0, GPT_CONFIG_124M[\"vocab_size\"], (2, 4)) # Create a batch of size (2, 4) with random token IDs"],"metadata":{"id":"SqyqlDj0LHsa","executionInfo":{"status":"ok","timestamp":1734244850963,"user_tz":-330,"elapsed":885,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Replace\n","torch.manual_seed(123)\n","out = model(batch)\n","print(\"Input batch:\\n\", batch)\n","print(\"\\nOutput shape:\", out.shape)\n","print(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Nut3l5PH9Ap","executionInfo":{"status":"ok","timestamp":1734244851586,"user_tz":-330,"elapsed":626,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"e7acc598-5ad0-48e4-c804-573943022807"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Input batch:\n"," tensor([[25371, 42188, 47556,  8856],\n","        [13224, 29264, 30628,  7204]])\n","\n","Output shape: torch.Size([2, 4, 50257])\n","tensor([[[-0.0961, -0.8734, -0.3528,  ...,  0.5963,  0.0828, -0.7096],\n","         [ 0.4491, -0.4307,  0.2018,  ..., -0.6829,  0.1718, -0.0297],\n","         [ 1.8269, -0.7455, -0.6371,  ...,  0.0712, -0.1257, -1.0365],\n","         [-0.8430, -0.1394,  0.9094,  ...,  0.3260,  0.1559, -0.5246]],\n","\n","        [[-0.2624,  0.5902,  0.7191,  ...,  0.1411,  0.1803, -0.9986],\n","         [-0.1118,  0.2005,  0.0073,  ..., -0.6253, -0.1632,  0.6767],\n","         [ 1.0571,  0.2045,  0.0262,  ...,  0.0043,  0.0270,  0.5476],\n","         [-0.8667, -0.1172,  0.8267,  ..., -0.0148, -0.9322,  0.1758]]],\n","       grad_fn=<UnsafeViewBackward0>)\n"]}]},{"cell_type":"markdown","source":["Using the numel() method, short for \"number of elements,\" we can collect the total number of parameters in the model's parameter tensors:"],"metadata":{"id":"jw8nwdJZMHFO"}},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total number of parameters: {total_params:,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Y3KJMkTLm3q","executionInfo":{"status":"ok","timestamp":1734244851586,"user_tz":-330,"elapsed":9,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"b76a580e-82de-47f0-9091-a11868eb6a92"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of parameters: 163,009,536\n"]}]},{"cell_type":"markdown","source":["The original GPT-2 architecture has 124 million parameter GPT model, so why is the actual number of parameters 163 million?\n","\n","The reason is original GPT-2 architecture is reusing the weights from the token embedding layer in its output layer."],"metadata":{"id":"sD7CBO1GMMpQ"}},{"cell_type":"markdown","source":["# GENERATING TEXT FROM OUTPUT TOKENS"],"metadata":{"id":"bPZ3ervKQOX6"}},{"cell_type":"code","source":["def generate_text_simple(model, idx, max_new_tokens, context_size):\n","    # idx is (batch, n_tokens) array of indices in the current context\n","\n","    ###Input batch:\n"," ###tensor([[6109, 3626, 6100,  345],\n","        ##[6109, 1110, 6622,  257]])\n","\n","    for _ in range(max_new_tokens):\n","\n","        # Crop current context if it exceeds the supported context size\n","        # E.g., if LLM supports only 5 tokens, and the context size is 10\n","        # then only the last 5 tokens are used as context\n","        idx_cond = idx[:, -context_size:]\n","\n","        # Get the predictions\n","        with torch.no_grad():\n","            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n","\n","        # Focus only on the last time step\n","        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n","        logits = logits[:, -1, :]\n","\n","        # Apply softmax to get probabilities\n","        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n","\n","        # Get the idx of the vocab entry with the highest probability value\n","        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n","\n","        # Append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n","\n","    return idx"],"metadata":{"id":"9YeX2CG24PbX","executionInfo":{"status":"ok","timestamp":1734244851586,"user_tz":-330,"elapsed":7,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Let's now try out the generate_text_simple function with the \"Hello, I am\" context as model input\n","\n","First, we encode the input context into token IDs:"],"metadata":{"id":"9xGMrcBJSheG"}},{"cell_type":"code","source":[],"metadata":{"id":"tpI9gM4k4OHd","executionInfo":{"status":"ok","timestamp":1734244851586,"user_tz":-330,"elapsed":6,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["start_context = \"Hello, I am\"\n","encoded = tokenizer.encode(start_context)\n","print(\"encoded:\", encoded)\n","encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n","print(\"encoded_tensor.shape:\", encoded_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNBde8qkSnqz","executionInfo":{"status":"ok","timestamp":1734244851586,"user_tz":-330,"elapsed":6,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"3c68e1a9-e126-45a0-8ae2-fe3342b8923a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["encoded: [15496, 11, 314, 716]\n","encoded_tensor.shape: torch.Size([1, 4])\n"]}]},{"cell_type":"markdown","source":["Next, we put the model into .eval() mode, which disables random components like dropout, which are only used during training, and use the generate_text_simple function on the encoded input tensor:"],"metadata":{"id":"TvBttN1HT6N8"}},{"cell_type":"code","source":["model.eval() #A\n","#model = GPTModel(GPT_CONFIG_124M)\n","out = generate_text_simple(\n","model=model,\n","idx=encoded_tensor,\n","max_new_tokens=6,  # 6 new tokens are generated you can change it according to your need\n","context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","print(\"Output:\", out)\n","print(\"Output length:\", len(out[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxM-9xw7Tw3V","executionInfo":{"status":"ok","timestamp":1734244852539,"user_tz":-330,"elapsed":956,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"e7b6de49-a0bc-4a22-d2ea-1d20f8f303a1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n","Output length: 10\n"]}]},{"cell_type":"markdown","source":["Using the .decode method of the tokenizer, we can convert the IDs back into text:"],"metadata":{"id":"NxCiwnPeUktR"}},{"cell_type":"code","source":["decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n","print(decoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qscg13bOUG6r","executionInfo":{"status":"ok","timestamp":1734244852539,"user_tz":-330,"elapsed":4,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"3f3b2501-ef6e-4b03-8ac9-929994bc0910"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, I am Featureiman Byeswickattribute argue\n"]}]},{"cell_type":"markdown","source":["As you can see above my model generate random text the reason is model can't traind yet"],"metadata":{"id":"JuJky8-oU6mr"}},{"cell_type":"code","source":["import torch\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Vocabulary size\n","    \"context_length\": 256, # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,        # Embedding dimension\n","    \"n_heads\": 12,         # Number of attention heads\n","    \"n_layers\": 12,        # Number of layers\n","    \"drop_rate\": 0.1,      # Dropout rate\n","    \"qkv_bias\": False      # Query-key-value bias\n","}\n","\n","torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.eval();  # Disable dropout during inference"],"metadata":{"id":"r8azR4e6VQSP","executionInfo":{"status":"ok","timestamp":1734244853155,"user_tz":-330,"elapsed":618,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["We reduce the context length (context_length) of only 256 tokens to reduce the computational resource requirements for training the model, whereas the original 124 million parameter GPT-2 model used 1024 tokens.\n","\n","Now we implement two functions, text_to_token_ids and token_ids_to_text, for converting between token and text representations that we use throughout"],"metadata":{"id":"mROojulXMNdP"}},{"cell_type":"code","source":["import tiktoken\n","\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n","    return encoded_tensor\n","\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0) # remove batch dimension\n","    return tokenizer.decode(flat.tolist())"],"metadata":{"id":"lGkTwGG_num6","executionInfo":{"status":"ok","timestamp":1734244853155,"user_tz":-330,"elapsed":3,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["start_context = \"Every effort moves you\"\n","\n","\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(start_context, tokenizer),\n","    max_new_tokens=10,\n","    context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WwoklcqMpQv","executionInfo":{"status":"ok","timestamp":1734244855127,"user_tz":-330,"elapsed":1974,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"42350635-0557-4576-c354-4904e7cad0b3"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"]}]},{"cell_type":"markdown","source":["As we can see above, the model does not produce good text because it has not been trained yet"],"metadata":{"id":"AC43L2yCMzC_"}},{"cell_type":"markdown","source":["# Calculating the text generation loss: cross-entropy and perplexity"],"metadata":{"id":"Z0DjUpjJM69l"}},{"cell_type":"code","source":["inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n","                       [40,    1107, 588]])   #  \"I really like\"]\n","\n","targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n","                        [1107,  588, 11311]]) #  \" really like chocolate\"]"],"metadata":{"id":"JZ7_XrjqMtzb","executionInfo":{"status":"ok","timestamp":1734244855127,"user_tz":-330,"elapsed":17,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    logits = model(inputs)\n","\n","probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n","print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emdsrnzEOaNf","executionInfo":{"status":"ok","timestamp":1734244855127,"user_tz":-330,"elapsed":17,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"4be35d12-fe69-4227-d5ff-8d44871298ef"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 50257])\n"]}]},{"cell_type":"code","source":["token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n","print(\"Token IDs:\\n\", token_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUlNIHg1OeE2","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":17,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"416d4009-7c81-463c-e322-f5c7bac2f477"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs:\n"," tensor([[[16657],\n","         [  339],\n","         [42826]],\n","\n","        [[49906],\n","         [29669],\n","         [41751]]])\n"]}]},{"cell_type":"code","source":["print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n","print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2_220wrOi2C","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":16,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"615bfcec-acce-4e5d-9beb-f6276fd3f1d1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Targets batch 1:  effort moves you\n","Outputs batch 1:  Armed heNetflix\n"]}]},{"cell_type":"markdown","source":["# Cross-entropy loss"],"metadata":{"id":"vVyMULlfOrka"}},{"cell_type":"code","source":["text_idx = 0\n","target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n","print(\"Text 1:\", target_probas_1)\n","\n","text_idx = 1\n","target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n","print(\"Text 2:\", target_probas_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVG8-NZPO0DO","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":14,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"35857225-18e7-4271-cce3-4dc1d66762a7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n","Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"]}]},{"cell_type":"code","source":["# Compute logarithm of all token probabilities\n","log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n","print(log_probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtccat9uO79-","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":12,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"850bc369-1873-4c7c-b2a3-75434bfe73a9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"]}]},{"cell_type":"markdown","source":["Next, we compute the average log probability:"],"metadata":{"id":"7aLpnPSDPGXA"}},{"cell_type":"code","source":["# Calculate the average probability for each token\n","avg_log_probas = torch.mean(log_probas)\n","print(avg_log_probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJ-MZqhvPCVD","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":11,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"128ff661-55e3-4479-902b-443a5aa0dad0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(-10.7940)\n"]}]},{"cell_type":"code","source":["neg_avg_log_probas = avg_log_probas * -1\n","print(neg_avg_log_probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTnWaXrjPKTJ","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":10,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"30325bc2-4d09-416d-d5a3-041b6dd0702d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10.7940)\n"]}]},{"cell_type":"code","source":["# Logits have shape (batch_size, num_tokens, vocab_size)\n","print(\"Logits shape:\", logits.shape)\n","\n","# Targets have shape (batch_size, num_tokens)\n","print(\"Targets shape:\", targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VpZ1sQkPOVN","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":9,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"8876ea7e-5ddb-436d-92f5-bca640d2363d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([2, 3, 50257])\n","Targets shape: torch.Size([2, 3])\n"]}]},{"cell_type":"code","source":["logits_flat = logits.flatten(0, 1)\n","targets_flat = targets.flatten()\n","\n","print(\"Flattened logits:\", logits_flat.shape)\n","print(\"Flattened targets:\", targets_flat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zONlkU-4PXA3","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":8,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"90edf5a2-84b9-47b7-de56-ae96ecb7b6e1"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Flattened logits: torch.Size([6, 50257])\n","Flattened targets: torch.Size([6])\n"]}]},{"cell_type":"code","source":["loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfJkP5WyPcys","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":6,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"46745a7c-1eb2-4e94-ea4f-0fb30b913069"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10.7940)\n"]}]},{"cell_type":"markdown","source":["Perplexit"],"metadata":{"id":"Z2nR9xBOSwAZ"}},{"cell_type":"markdown","source":["Low Perplexity: Indicates that the model assigns high probabilities to the actual words in the sequence, implying better predictions.\n","High Perplexity: Suggests that the model is uncertain or incorrect in predicting the next word."],"metadata":{"id":"5F5RbZd3Stmk"}},{"cell_type":"code","source":["perplexity = torch.exp(loss)\n","print(perplexity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BrEa6zLPgu5","executionInfo":{"status":"ok","timestamp":1734244855128,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"e2ee3cbf-fddc-4a7a-8abb-6ec2df8ce49a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(48725.8203)\n"]}]},{"cell_type":"markdown","source":["Above perplexity value of 48725.8203 is extremely high, which indicates that your model is struggling to predict the text well."],"metadata":{"id":"sDWk271oTa8s"}},{"cell_type":"markdown","source":["# Calculating the training and validation set losses"],"metadata":{"id":"_-lcz62SsxzO"}},{"cell_type":"markdown","source":["We use a relatively small dataset for training the LLM (in fact, only one short story)\n","\n","So that I can run the code examples in a few minutes on a laptop computer without a suitable GPU."],"metadata":{"id":"TZDhyBsks7Ao"}},{"cell_type":"code","source":["import os\n","import urllib.request\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","    with urllib.request.urlopen(url) as response:\n","        text_data = response.read().decode('utf-8')\n","    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_data)\n","else:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        text_data = file.read()"],"metadata":{"id":"3c_PKXTdriB1","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":615,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# First 100 characters\n","print(text_data[:99])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7qMdDIHtVFl","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":12,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"47ab83af-27e8-4711-ed75-92befc8371a7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}]},{"cell_type":"code","source":["total_characters = len(text_data)\n","total_tokens = len(tokenizer.encode(text_data))\n","\n","print(\"Characters:\", total_characters)\n","print(\"Tokens:\", total_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-kW1ebKtWT1","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":10,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"09d898e9-bcb3-4ee5-eced-f3fcfc166d4c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Characters: 20479\n","Tokens: 5145\n"]}]},{"cell_type":"markdown","source":["With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later).\n"],"metadata":{"id":"-2jD5v4VuhHg"}},{"cell_type":"markdown","source":["# Implementing the DataLoader:"],"metadata":{"id":"R98rHWbw18sY"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","class GPTDatasetV1(Dataset):\n","    def __init__(self, txt, tokenizer, max_length, stride):\n","        self.input_ids = []\n","        self.target_ids = []\n","\n","        # Tokenize the entire text\n","        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n","\n","        # Use a sliding window to chunk the book into overlapping sequences of max_length\n","        for i in range(0, len(token_ids) - max_length, stride):\n","            input_chunk = token_ids[i:i + max_length]\n","            target_chunk = token_ids[i + 1: i + max_length + 1]\n","            self.input_ids.append(torch.tensor(input_chunk))\n","            self.target_ids.append(torch.tensor(target_chunk))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","\n","def create_dataloader_v1(txt, batch_size=4, max_length=256,\n","                         stride=128, shuffle=True, drop_last=True,\n","                         num_workers=0):\n","\n","    # Initialize the tokenizer\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create dataset\n","    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n","\n","    # Create dataloader\n","    dataloader = DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers\n","    )\n","\n","    return dataloader"],"metadata":{"id":"13IBlmjNt0VS","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":8,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Train/validation ratio\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=False,\n","    shuffle=False,\n","    num_workers=0\n",")"],"metadata":{"id":"5DGwJfQZ2B5g","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":7,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Sanity check\n","\n","if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n","    print(\"Not enough tokens for the training loader. \"\n","          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n","          \"increase the `training_ratio`\")\n","\n","if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n","    print(\"Not enough tokens for the validation loader. \"\n","          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n","          \"decrease the `training_ratio`\")"],"metadata":{"id":"XTLlpPfT2n-F","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":7,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["print(\"Train loader:\")\n","for x, y in train_loader:\n","    print(x.shape, y.shape)\n","\n","print(\"\\nValidation loader:\")\n","for x, y in val_loader:\n","    print(x.shape, y.shape)\n","\n","print(len(train_loader))\n","print(len(val_loader))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHs43s5I5C2Q","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":7,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"3056a014-f701-4a35-e60d-1fb6069d025b"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loader:\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","\n","Validation loader:\n","torch.Size([2, 256]) torch.Size([2, 256])\n","9\n","1\n"]}]},{"cell_type":"code","source":["train_tokens = 0\n","for input_batch, target_batch in train_loader:\n","    train_tokens += input_batch.numel()\n","\n","val_tokens = 0\n","for input_batch, target_batch in val_loader:\n","    val_tokens += input_batch.numel()\n","\n","print(\"Training tokens:\", train_tokens)\n","print(\"Validation tokens:\", val_tokens)\n","print(\"All tokens:\", train_tokens + val_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRDKFvZ15Ygx","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"f27c5f0e-61c5-4f81-e4c0-2870c0e5c5bd"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Training tokens: 4608\n","Validation tokens: 512\n","All tokens: 5120\n"]}]},{"cell_type":"markdown","source":["Now we implement a utility function to calculate the cross-entropy loss of a given batch."],"metadata":{"id":"6avfjuve768z"}},{"cell_type":"markdown","source":["In addition, we also implement a second utility function to compute the loss for a user-specified number of batches in a data loader."],"metadata":{"id":"IHeL-kgg8Dem"}},{"cell_type":"code","source":["def calc_loss_batch(input_batch, target_batch, model, device):\n","    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n","    logits = model(input_batch)\n","    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n","    return loss\n","\n","\n","def calc_loss_loader(data_loader, model, device, num_batches=None):\n","    total_loss = 0.\n","    if len(data_loader) == 0:\n","        return float(\"nan\")\n","    elif num_batches is None:\n","        num_batches = len(data_loader)\n","    else:\n","        # Reduce the number of batches to match the total number of batches in the data loader\n","        # if num_batches exceeds the number of batches in the data loader\n","        num_batches = min(num_batches, len(data_loader))\n","    for i, (input_batch, target_batch) in enumerate(data_loader):\n","        if i < num_batches:\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            total_loss += loss.item()\n","        else:\n","            break\n","    return total_loss / num_batches"],"metadata":{"id":"az5bFfoc5oZb","executionInfo":{"status":"ok","timestamp":1734244855739,"user_tz":-330,"elapsed":4,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n","\n","\n","torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n","\n","with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n","    train_loss = calc_loss_loader(train_loader, model, device)\n","    val_loss = calc_loss_loader(val_loader, model, device)\n","\n","print(\"Training loss:\", train_loss)\n","print(\"Validation loss:\", val_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVG5S-M19rFL","executionInfo":{"status":"ok","timestamp":1734244858231,"user_tz":-330,"elapsed":2495,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"7be933bc-fb05-4f29-ea27-93820b15df35"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Training loss: 10.987583266364204\n","Validation loss: 10.981104850769043\n"]}]},{"cell_type":"markdown","source":["Here wo got loss now we will using backparpogation and try to minimize the loss"],"metadata":{"id":"IlRwnMsy-oKP"}},{"cell_type":"markdown","source":["# TRAINING LOOP FOR THE LLM"],"metadata":{"id":"rDVFpg46-YT3"}},{"cell_type":"markdown","source":["The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training."],"metadata":{"id":"hxsamArojlRd"}},{"cell_type":"code","source":["def generate_and_print_sample(model, tokenizer, device, start_context):\n","    model.eval()\n","    context_size = model.pos_emb.weight.shape[0]\n","    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n","    with torch.no_grad():\n","        token_ids = generate_text_simple(\n","            model=model, idx=encoded,\n","            max_new_tokens=50, context_size=context_size\n","        )\n","    decoded_text = token_ids_to_text(token_ids, tokenizer)\n","    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n","    model.train()"],"metadata":{"id":"0dc9vWZ09yYC","executionInfo":{"status":"ok","timestamp":1734244858232,"user_tz":-330,"elapsed":5,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n","                       eval_freq, eval_iter, start_context, tokenizer):\n","    # Initialize lists to track losses and tokens seen\n","    train_losses, val_losses, track_tokens_seen = [], [], []\n","    tokens_seen, global_step = 0, -1\n","\n","    # Main training loop\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","\n","        for input_batch, target_batch in train_loader:\n","            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward() # Calculate loss gradients\n","            optimizer.step() # Update model weights using loss gradients\n","            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n","            global_step += 1\n","\n","            # Optional evaluation step\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(\n","                    model, train_loader, val_loader, device, eval_iter)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","                track_tokens_seen.append(tokens_seen)\n","                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n","\n","        # Print a sample text after each epoch\n","        generate_and_print_sample(\n","            model, tokenizer, device, start_context\n","        )\n","\n","    return train_losses, val_losses, track_tokens_seen"],"metadata":{"id":"PvfrivDYjmZT","executionInfo":{"status":"ok","timestamp":1734244858232,"user_tz":-330,"elapsed":4,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n","        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n","    model.train()\n","    return train_loss, val_loss"],"metadata":{"id":"ZNA9BLnhjq_K","executionInfo":{"status":"ok","timestamp":1734244858232,"user_tz":-330,"elapsed":4,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW optimizer and the train_model_simple function we defined earlier."],"metadata":{"id":"3srX6Z1HrtJM"}},{"cell_type":"code","source":["import time\n","start_time = time.time()\n","\n","torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n","num_epochs = 10\n","train_losses, val_losses, tokens_seen = train_model_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n","    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",")\n","end_time = time.time()\n","execution_time_minutes = (end_time - start_time) / 60\n","print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AuJ-xa1RqinC","executionInfo":{"status":"ok","timestamp":1734244892776,"user_tz":-330,"elapsed":34548,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"a003f2b3-fc1e-4f46-b46e-0a8a65c6a812"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n","Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n","Every effort moves you,,,,,,,,,,,,.                                     \n","Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n","Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n","Every effort moves you, and,, and,,,,,,, and,.                                   \n","Ep 3 (Step 000020): Train loss 5.532, Val loss 6.507\n","Ep 3 (Step 000025): Train loss 5.399, Val loss 6.389\n","Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n","Ep 4 (Step 000030): Train loss 4.895, Val loss 6.280\n","Ep 4 (Step 000035): Train loss 4.648, Val loss 6.304\n","Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n","Ep 5 (Step 000040): Train loss 4.023, Val loss 6.165\n","Every effort moves you know                                                 \n","Ep 6 (Step 000045): Train loss 3.625, Val loss 6.172\n","Ep 6 (Step 000050): Train loss 3.045, Val loss 6.144\n","Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n","Ep 7 (Step 000055): Train loss 2.948, Val loss 6.183\n","Ep 7 (Step 000060): Train loss 2.230, Val loss 6.128\n","Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n","Ep 8 (Step 000065): Train loss 1.774, Val loss 6.162\n","Ep 8 (Step 000070): Train loss 1.475, Val loss 6.229\n","Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n","Ep 9 (Step 000075): Train loss 1.135, Val loss 6.268\n","Ep 9 (Step 000080): Train loss 0.858, Val loss 6.298\n","Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n","Ep 10 (Step 000085): Train loss 0.627, Val loss 6.382\n","Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n","Training completed in 0.58 minutes.\n"]}]},{"cell_type":"markdown","source":["As we can see, based on the results printed during the training, the training loss improves drastically, starting with a value of 9.783 and converging to 0.506."],"metadata":{"id":"AaM54ypZx25j"}},{"cell_type":"markdown","source":["Now, Let's create a simple plot that shows the training and validation set losses side by side"],"metadata":{"id":"QPNk5YDEyt3o"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","\n","\n","def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n","    fig, ax1 = plt.subplots(figsize=(5, 3))\n","\n","    # Plot training and validation loss against epochs\n","    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n","    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n","    ax1.set_xlabel(\"Epochs\")\n","    ax1.set_ylabel(\"Loss\")\n","    ax1.legend(loc=\"upper right\")\n","    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n","\n","    # Create a second x-axis for tokens seen\n","    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n","    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n","    ax2.set_xlabel(\"Tokens seen\")\n","\n","    fig.tight_layout()  # Adjust layout to make room\n","    plt.savefig(\"loss-plot.pdf\")\n","    plt.show()\n","\n","epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"KCQAvkPRr4x6","executionInfo":{"status":"ok","timestamp":1734244893836,"user_tz":-330,"elapsed":1063,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"0018560d-eb7e-48e3-89dc-dba9a9458f0e"},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["As you can see that validation loss is not decreasing after some epochs it is the clear sign of overfitting, It happen because model memorizes the training data, This memorization is expected because we are working with a very, very small training dataset and training the model for multiple epochs."],"metadata":{"id":"6bS1pRAHy7FL"}},{"cell_type":"markdown","source":["its not possible for me to train this model and find optimal weights for all parameters because we need large amout of data and too much computationl cost"],"metadata":{"id":"xSDkTBoq-313"}},{"cell_type":"markdown","source":["So we use the pre train weigth which are already provided by Openai of GPT 2"],"metadata":{"id":"TGslukzx_UDI"}},{"cell_type":"markdown","source":["Merge Temperature Scaling and Top-k sampling"],"metadata":{"id":"QE-Vd8hxFsiO"}},{"cell_type":"code","source":["def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","\n","    # For-loop is the same as before: Get logits, and only focus on last time step\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # New: Filter logits with top_k sampling\n","        if top_k is not None:\n","            # Keep only top_k values\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n","\n","        # New: Apply temperature scaling\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Apply softmax to get probabilities\n","            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n","\n","            # Sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n","\n","        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n","\n","        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","            break\n","\n","        # Same as before: append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n","\n","    return idx"],"metadata":{"id":"67NGwP-yFtpz","executionInfo":{"status":"ok","timestamp":1734245562140,"user_tz":-330,"elapsed":621,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":["# LOADING AND SAVING MODEL WEIGHTS IN PYTORCH"],"metadata":{"id":"LLhfHSh__xsq"}},{"cell_type":"code","source":["model = GPTModel(GPT_CONFIG_124M)\n","torch.save(model.state_dict(), \"model.pth\")"],"metadata":{"id":"FFyG1B7D7837","executionInfo":{"status":"ok","timestamp":1734244898464,"user_tz":-330,"elapsed":4633,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["In the preceding code, \"model.pth\" is the filename where the state_dict is saved."],"metadata":{"id":"b3-qfK4B_9gY"}},{"cell_type":"markdown","source":["Then, after saving the model weights via the state_dict, we can load the model weights into a new GPTModel model instance as follows"],"metadata":{"id":"vt4CxlIoAG0u"}},{"cell_type":"code","source":["model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(torch.load(\"model.pth\"))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsAbutZeAA_t","executionInfo":{"status":"ok","timestamp":1734244900096,"user_tz":-330,"elapsed":1635,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"8f59c9b8-a392-4da5-f756-0fca75b80546"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-48-f3ec32668201>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"model.pth\"))\n"]},{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(256, 768)\n","  (drop_emb): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (att): MultiHeadAttention(\n","        (W_query): Linear(in_features=768, out_features=768, bias=False)\n","        (W_key): Linear(in_features=768, out_features=768, bias=False)\n","        (W_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ff): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (norm1): LayerNorm()\n","      (norm2): LayerNorm()\n","      (drop_shortcut): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["Using torch.save, we can save both the model and optimizer state_dict contents as follows"],"metadata":{"id":"hgh1kFmTAiGx"}},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n","\n","torch.save({\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict(),\n","    },\n","    \"model_and_optimizer.pth\"\n",")"],"metadata":{"id":"OT8TcFZiAPFU","executionInfo":{"status":"ok","timestamp":1734244905487,"user_tz":-330,"elapsed":5394,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["Then, we can restore the model and optimizer states as follows by first loading the saved data via torch.load and then using the load_state_dict method:\n"],"metadata":{"id":"3647UJYOBAWR"}},{"cell_type":"code","source":["checkpoint = torch.load(\"model_and_optimizer.pth\")\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","model.train();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXJcfFzVAl4c","executionInfo":{"status":"ok","timestamp":1734244907325,"user_tz":-330,"elapsed":1840,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"67334a95-45d4-461e-c664-a57d6e66225b"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-50-463cac8a72b4>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(\"model_and_optimizer.pth\")\n"]}]},{"cell_type":"markdown","source":["# LOADING PRETRAINED WEIGHTS FROM OPENAI"],"metadata":{"id":"0Csqrn6uBJbw"}},{"cell_type":"markdown","source":["Previously, for educational purposes, we trained a small GPT-2 model using a limited dataset comprising a short-story book.\n","\n","Fortunately, OpenAI openly shared the weights of their GPT-2 models, thus eliminating the need to invest tens to hundreds of thousands of dollars in retraining the model on a large corpus ourselves."],"metadata":{"id":"jVe12_ExBQWb"}},{"cell_type":"code","source":["pip install tensorflow>=2.15.0 tqdm>=4.66"],"metadata":{"id":"o3a6_WXRBDPh","executionInfo":{"status":"ok","timestamp":1734244910547,"user_tz":-330,"elapsed":3225,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tqdm\n","\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"tqdm version:\", tqdm.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvn_Fe1bBsUw","executionInfo":{"status":"ok","timestamp":1734244913468,"user_tz":-330,"elapsed":2927,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"91b029d5-d6b3-4d88-9805-f99611c10660"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.17.1\n","tqdm version: 4.66.6\n"]}]},{"cell_type":"markdown","source":["We can now import the download_and_load_gpt2 function from the gpt_download.py file as follows, which will load the GPT-2 architecture settings (settings) and weight parameters (params) into our Python session"],"metadata":{"id":"qM9LnrUTDrCf"}},{"cell_type":"code","source":["from gpt_download3 import download_and_load_gpt2"],"metadata":{"id":"UGvUgVGABxCe","executionInfo":{"status":"ok","timestamp":1734244938021,"user_tz":-330,"elapsed":617,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5Umff2wB25d","executionInfo":{"status":"ok","timestamp":1734245026844,"user_tz":-330,"elapsed":82160,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"c31bd24f-c355-4e94-d44b-308c90bf2494"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 92.6kiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 633kiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 232kiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:11<00:00, 6.99MiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 3.48MiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 388kiB/s]\n","/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n","vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 323kiB/s]\n"]}]},{"cell_type":"code","source":["print(\"Settings:\", settings)\n","print(\"Parameter dictionary keys:\", params.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oda9kYTgDs2q","executionInfo":{"status":"ok","timestamp":1734245039845,"user_tz":-330,"elapsed":867,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"5d08f702-d30c-462c-bcc1-cb746da2b776"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n","Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"]}]},{"cell_type":"markdown","source":["Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our GPTModel instance.\n","\n","First, we initialize a new GPTModel instance.\n","\n","Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting qkv_bias to True in our implementation, too.\n","\n","We are also using the 1024 token context length that was used by the original GPT-2 model(s)"],"metadata":{"id":"AzJH21_LEgPG"}},{"cell_type":"code","source":["model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","# Copy the base configuration and update with specific model settings\n","model_name = \"gpt2-small (124M)\"  # Example model name\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])"],"metadata":{"id":"JXUEJIARDzUN","executionInfo":{"status":"ok","timestamp":1734245044709,"user_tz":-330,"elapsed":872,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["we used a 256-token length earlier, but the original GPT-2 models from OpenAI were trained with a 1,024-token length, so we have to update the NEW_CONFIG accordingly:"],"metadata":{"id":"e_DquGjZFA5y"}},{"cell_type":"markdown","source":["Also do qkv = TRUE"],"metadata":{"id":"5YDNOuj9FR8u"}},{"cell_type":"code","source":["NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval();"],"metadata":{"id":"0hP_iBToE2Le","executionInfo":{"status":"ok","timestamp":1734245050857,"user_tz":-330,"elapsed":1610,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["def assign(left, right):\n","    if left.shape != right.shape:\n","        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n","    return torch.nn.Parameter(torch.tensor(right))"],"metadata":{"id":"2MphyQ8ID2BD","executionInfo":{"status":"ok","timestamp":1734245219906,"user_tz":-330,"elapsed":888,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["Next, we define a load_weights_into_gpt function that loads the weights from the params dictionary into a GPTModel instance gpt:"],"metadata":{"id":"BduqqBHIEjp_"}},{"cell_type":"code","source":["def load_weights_into_gpt(gpt, params):\n","    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n","    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.weight = assign(\n","            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n","        gpt.trf_blocks[b].att.W_key.weight = assign(\n","            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n","        gpt.trf_blocks[b].att.W_value.weight = assign(\n","            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.bias = assign(\n","            gpt.trf_blocks[b].att.W_query.bias, q_b)\n","        gpt.trf_blocks[b].att.W_key.bias = assign(\n","            gpt.trf_blocks[b].att.W_key.bias, k_b)\n","        gpt.trf_blocks[b].att.W_value.bias = assign(\n","            gpt.trf_blocks[b].att.W_value.bias, v_b)\n","\n","        gpt.trf_blocks[b].att.out_proj.weight = assign(\n","            gpt.trf_blocks[b].att.out_proj.weight,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].att.out_proj.bias = assign(\n","            gpt.trf_blocks[b].att.out_proj.bias,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[0].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[0].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[2].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[2].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].norm1.scale = assign(\n","            gpt.trf_blocks[b].norm1.scale,\n","            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.trf_blocks[b].norm1.shift = assign(\n","            gpt.trf_blocks[b].norm1.shift,\n","            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.trf_blocks[b].norm2.scale = assign(\n","            gpt.trf_blocks[b].norm2.scale,\n","            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.trf_blocks[b].norm2.shift = assign(\n","            gpt.trf_blocks[b].norm2.shift,\n","            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n","    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n","    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n","\n"],"metadata":{"id":"8WYxaFzoEfdW","executionInfo":{"status":"ok","timestamp":1734245265502,"user_tz":-330,"elapsed":888,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"PLBqN9EaE0tN","executionInfo":{"status":"ok","timestamp":1734245317092,"user_tz":-330,"elapsed":2,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["load_weights_into_gpt(gpt, params)\n","gpt.to(device);"],"metadata":{"id":"8P0rKP0kEqlr","executionInfo":{"status":"ok","timestamp":1734245321150,"user_tz":-330,"elapsed":606,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":["Now , its time to generate new next by using preious generate function"],"metadata":{"id":"KRLtdKICMVjd"}},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","token_ids = generate(\n","    model=gpt,\n","    idx=text_to_token_ids(\"hard work in study increase your\", tokenizer).to(device),\n","    max_new_tokens=25,\n","    context_size=NEW_CONFIG[\"context_length\"],\n","    top_k=50,\n","    temperature=0.8\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HzJHLUPE8I2","executionInfo":{"status":"ok","timestamp":1734247089887,"user_tz":-330,"elapsed":840,"user":{"displayName":"Syed Sadiq Raza","userId":"16904304800346490741"}},"outputId":"8b4fe6c4-2d02-444b-b8a7-28cf1038a8c5"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," hard work in study increase your chances of success, and you might be more likely to be able to succeed with more difficult work.\n","\n","You can also\n"]}]}]}